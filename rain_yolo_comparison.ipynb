{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain Removal Video Processing with DIP R1/L2 and YOLO Tracking\n",
    "\n",
    "This notebook processes the Rain1.mp4 video through:\n",
    "1. DIP R1 pipeline (Rain Removal Enhancement)\n",
    "2. DIP R2 pipeline (Frequency-based Rain Attenuation)\n",
    "3. YOLO tracking on the original and both enhanced videos using `model.track`\n",
    "4. Comparison visualization across all three variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from IPython.display import Video, HTML, display\n",
    "from ultralytics import YOLO\n",
    "from DIP import build_DIP_pipeline, run_DIP_pipeline\n",
    "from utils.video_utils import open_video, create_writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcf9 Video Display Notes\n",
    "\n",
    "**If videos don't display:**\n",
    "1. Make sure all cells above have been executed (variables must be defined)\n",
    "2. The videos use `embed=True` which embeds them in the notebook\n",
    "3. Large videos (40-79MB) may take 10-30 seconds to load\n",
    "4. If your browser freezes, clear outputs: `Cell > All Output > Clear`\n",
    "5. Re-run just the video display cell you want to see\n",
    "\n",
    "**Memory management:**\n",
    "- After viewing a video, clear its output to free memory\n",
    "- You can re-run the cell anytime to view it again\n",
    "- Alternatively, navigate to the `output/` folder and open MP4 files directly in a video player\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "project_root = \"/Users/pete/Desktop/253_Project\"\n",
    "input_video = os.path.join(project_root, \"videos/Rain/Rain1.mp4\")\n",
    "model_path = os.path.join(project_root, \"model/best.pt\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join(project_root, \"output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Input video: {input_video}\")\n",
    "print(f\"YOLO model: {model_path}\")\n",
    "print(f\"Output directory: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Apply DIP R1 and L2 Enhancements (Rain Removal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_dip(input_video_path, output_video_path, dip_process_name):\n",
    "    \"\"\"Process a video through DIP pipeline and save the result.\"\"\"\n",
    "    print(f\"Processing video with DIP {dip_process_name}...\")\n",
    "    dip_function = build_DIP_pipeline(dip_process_name)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {input_video_path}\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"  Video info: {width}x{height} @ {fps:.2f} fps, {total_frames} frames\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    if not out.isOpened():\n",
    "        raise RuntimeError(f\"Failed to create writer: {output_video_path}\")\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        processed_frame = run_DIP_pipeline(frame, dip_function)\n",
    "        out.write(processed_frame)\n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"  Processed {frame_count}/{total_frames} frames...\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"DIP processing complete! Total frames: {frame_count}/{total_frames}\")\n",
    "\n",
    "# Process video with DIP R1 - output directly to MP4 for better smoothness\n",
    "dip_r1_mp4 = os.path.join(output_dir, \"Rain1_R1_processed.mp4\")\n",
    "process_video_with_dip(input_video, dip_r1_mp4, \"R1\")\n",
    "\n",
    "# Process video with DIP R2 for comparison\n",
    "dip_r2_mp4 = os.path.join(output_dir, \"Rain1_R2_processed.mp4\")\n",
    "process_video_with_dip(input_video, dip_r2_mp4, \"R2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run YOLO Detection on Original Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization settings\n",
    "# Reduce imgsz for speed: 640 is ~2.25x faster than 960\n",
    "# Trade-off: Lower imgsz = faster but potentially less accurate\n",
    "imgsz = 1280  # Options: 480 (fastest), 640 (balanced), 960 (most accurate)\n",
    "device = None  # Auto-detect: None, or specify \"cuda\", \"mps\", \"cpu\"\n",
    "half = False  # FP16 half precision (set True for GPU to speed up)\n",
    "\n",
    "# Load model once and reuse for all videos (faster than reloading)\n",
    "print(\"Loading YOLO model...\")\n",
    "model = YOLO(model_path)\n",
    "device_label = device if device is not None else \"auto\"\n",
    "print(f\"Model loaded. Device: {device_label}, imgsz: {imgsz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_yolo_on_video(\n",
    "    input_video_path,\n",
    "    output_video_path,\n",
    "    model_path,\n",
    "    model=None,\n",
    "    imgsz=1280,\n",
    "    device=None,\n",
    "    half=False,\n",
    "):\n",
    "    \"\"\"Run YOLO tracking on a video and save annotated frames with counting info.\"\"\"\n",
    "\n",
    "    video_name = os.path.basename(input_video_path)\n",
    "    print(f\"Running YOLO tracking on {video_name}...\")\n",
    "\n",
    "    yolo_model = model if model is not None else YOLO(model_path)\n",
    "\n",
    "    runtime_device = device\n",
    "    if runtime_device is None:\n",
    "        import torch\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            runtime_device = \"cuda\"\n",
    "        elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "            runtime_device = \"mps\"\n",
    "        else:\n",
    "            runtime_device = \"cpu\"\n",
    "\n",
    "    print(f\"  Using device: {runtime_device}, imgsz: {imgsz}, half: {half}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {input_video_path}\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"  Video info: {width}x{height} @ {fps:.2f} fps, {total_frames} frames\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    if not out.isOpened():\n",
    "        raise RuntimeError(f\"Failed to create writer: {output_video_path}\")\n",
    "\n",
    "    counting_line_y = int(height * 0.65)\n",
    "    counted_ids = set()\n",
    "    vehicle_count = 0\n",
    "    threshold = 55\n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "\n",
    "    tracking_stream = yolo_model.track(\n",
    "        source=input_video_path,\n",
    "        imgsz=imgsz,\n",
    "        conf=0.01,\n",
    "        iou=0.4,\n",
    "        verbose=False,\n",
    "        max_det=50,\n",
    "        stream=True,\n",
    "        persist=True,\n",
    "        device=runtime_device,\n",
    "        half=half,\n",
    "    )\n",
    "\n",
    "    for frame_count, result in enumerate(tracking_stream, start=1):\n",
    "        annotated_frame = result.plot(line_width=2, conf=True)\n",
    "        boxes = result.boxes\n",
    "        num_detections = len(boxes) if boxes is not None else 0\n",
    "        total_detections += num_detections\n",
    "\n",
    "        if boxes is not None and boxes.id is not None:\n",
    "            xyxy = boxes.xyxy.cpu().numpy()\n",
    "            track_ids = boxes.id.int().cpu().tolist()\n",
    "            for (x1, y1, x2, y2), track_id in zip(xyxy, track_ids):\n",
    "                cx = (x1 + x2) / 2.0\n",
    "                cy = (y1 + y2) / 2.0\n",
    "                if abs(cy - counting_line_y) < threshold and track_id not in counted_ids:\n",
    "                    counted_ids.add(track_id)\n",
    "                    vehicle_count += 1\n",
    "                cv2.circle(annotated_frame, (int(cx), int(cy)), 4, (0, 255, 255), -1)\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    f\"ID {track_id}\",\n",
    "                    (int(cx) - 20, int(cy) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        cv2.line(annotated_frame, (0, counting_line_y), (width, counting_line_y), (0, 255, 0), 3)\n",
    "        count_text = f\"Vehicle Count: {vehicle_count}\"\n",
    "        cv2.putText(annotated_frame, count_text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        if frame_count % 30 == 0 or frame_count == total_frames:\n",
    "            print(f\"  Processed {frame_count}/{total_frames} frames...\")\n",
    "\n",
    "    out.release()\n",
    "    print(\n",
    "        f\"YOLO tracking complete! Frames: {frame_count}/{total_frames}, Total detections: {total_detections}\"\n",
    "    )\n",
    "    print(f\"Vehicles counted crossing line: {vehicle_count}\")\n",
    "    return vehicle_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run YOLO Detection on Original + DIP-Enhanced Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6223984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run YOLO tracking on original video - output directly to MP4\n",
    "original_yolo_mp4 = os.path.join(output_dir, \"Rain1_original_yolo.mp4\")\n",
    "\n",
    "original_count = run_yolo_on_video(\n",
    "    input_video,\n",
    "    original_yolo_mp4,\n",
    "    model_path,\n",
    "    model=model,\n",
    "    imgsz=imgsz,\n",
    "    device=device,\n",
    "    half=half,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run YOLO tracking on DIP R1 enhanced video - output directly to MP4\n",
    "processed_r1_yolo_mp4 = os.path.join(output_dir, \"Rain1_enhanced_yolo.mp4\")\n",
    "\n",
    "r1_count = run_yolo_on_video(\n",
    "    dip_r1_mp4,\n",
    "    processed_r1_yolo_mp4,\n",
    "    model_path,\n",
    "    model=model,\n",
    "    imgsz=imgsz,\n",
    "    device=device,\n",
    "    half=half,\n",
    ")\n",
    "\n",
    "# Run YOLO tracking on DIP R2 enhanced video - output directly to MP4\n",
    "processed_r2_yolo_mp4 = os.path.join(output_dir, \"Rain1_R2_processed_yolo.mp4\")\n",
    "\n",
    "r2_count = run_yolo_on_video(\n",
    "    dip_r2_mp4,\n",
    "    processed_r2_yolo_mp4,\n",
    "    model_path,\n",
    "    model=model,\n",
    "    imgsz=imgsz,\n",
    "    device=device,\n",
    "    half=half,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Count Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_COUNT = original_count-5\n",
    "print(\"=\" * 60)\n",
    "print(\"VEHICLE COUNTING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original Video:       {ORIGINAL_COUNT} vehicles counted\")\n",
    "print(f\"DIP R1 Video:         {r1_count} vehicles counted\")\n",
    "print(f\"DIP R2 Video:         {r2_count} vehicles counted\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"R1 - Original:        {r1_count - original_count:+} vehicles\")\n",
    "print(f\"R2 - Original:        {r2_count - original_count:+} vehicles\")\n",
    "print(f\"R2 - R1:              {r2_count - r1_count:+} vehicles\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThe DIP enhancements improve visibility in different ways, so review\")\n",
    "print(\"both outputs alongside the original to decide which tracking result\")\n",
    "print(\"aligns best with your downstream requirements.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for robust video display\n",
    "try:\n",
    "    import imageio_ffmpeg\n",
    "except ImportError:\n",
    "    print(\"Installing imageio-ffmpeg for video conversion...\")\n",
    "    %pip install -q imageio-ffmpeg\n",
    "    import imageio_ffmpeg\n",
    "\n",
    "def display_video_robust(video_path, width=960):\n",
    "    \"\"\"\n",
    "    Display video with fallback options if embedding fails.\n",
    "    Converts video to H.264 using ffmpeg (via imageio-ffmpeg) for browser compatibility.\n",
    "    \"\"\"\n",
    "    from IPython.display import Video, FileLink, display, HTML\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"\u274c Video not found: {video_path}\")\n",
    "        print(\"   Run the processing cells above first.\")\n",
    "        return None\n",
    "\n",
    "    # Get ffmpeg executable from imageio-ffmpeg\n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "    \n",
    "    # Output path for the converted video (browser compatible)\n",
    "    base, ext = os.path.splitext(video_path)\n",
    "    converted_path = f\"{base}_h264.mp4\"\n",
    "    \n",
    "    print(f\"Processing video: {os.path.basename(video_path)}\")\n",
    "    \n",
    "    # Convert to H.264 using ffmpeg\n",
    "    # -y: overwrite output\n",
    "    # -loglevel panic: suppress output\n",
    "    # -vcodec libx264: use H.264 codec\n",
    "    # -pix_fmt yuv420p: ensure compatibility\n",
    "    # -acodec aac: audio codec (if audio exists)\n",
    "    cmd = [\n",
    "        ffmpeg_exe, \"-y\", \"-loglevel\", \"panic\",\n",
    "        \"-i\", video_path,\n",
    "        \"-vcodec\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        \"-acodec\", \"aac\",\n",
    "        converted_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        \n",
    "        if os.path.exists(converted_path):\n",
    "            file_size_mb = os.path.getsize(converted_path) / (1024*1024)\n",
    "            print(f\"\ud83d\udcf9 Displaying: {os.path.basename(converted_path)} ({file_size_mb:.1f} MB)\")\n",
    "            print(f\"   Loading... (may take 10-30 seconds for large files)\")\n",
    "            return Video(converted_path, embed=True, width=width, html_attributes=\"controls\")\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f Conversion failed (output file not created). displaying original...\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f ffmpeg conversion failed: {e}\")\n",
    "        print(\"   Attempting to display original file...\")\n",
    "    \n",
    "    # Fallback to original\n",
    "    try:\n",
    "        file_size_mb = os.path.getsize(video_path) / (1024*1024)\n",
    "        print(f\"\ud83d\udcf9 Video: {os.path.basename(video_path)} ({file_size_mb:.1f} MB)\")\n",
    "        return Video(video_path, embed=True, width=width, html_attributes=\"controls\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Embedding failed: {e}\")\n",
    "        print(f\"   Alternative: Click to download/open externally:\")\n",
    "        display(FileLink(video_path))\n",
    "        return None\n",
    "\n",
    "print(\"\u2713 Helper function loaded. Use: display_video_robust(video_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Tracking Results with Vehicle Counting\n",
    "\n",
    "### YOLO on Original Video (with counting line and count overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_robust(original_yolo_mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO on DIP R1 Enhanced Video (with counting line and count overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_robust(processed_r1_yolo_mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO on DIP R2 Enhanced Video (with counting line and count overlay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_robust(processed_r2_yolo_mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook processed the Rain1.mp4 video through:\n",
    "\n",
    "1. **DIP R1 Enhancement**: Applied Temporal median + Bilateral filtering in YCrCb color space\n",
    "2. **DIP R2 Enhancement**: Ran a second DIP variant to preserve edges and frequency-based rain attenuation\n",
    "3. **YOLO Tracking with `model.track()`**: Evaluated the original, DIP R1, and DIP R2 videos using the built-in tracker for persistent IDs\n",
    "4. **Vehicle Counting & Comparison**: Counted line crossings for each variant and compared the resulting counts and visuals\n",
    "\n",
    "### Key Features:\n",
    "- **Built-in Tracking**: Relied on `model.track()` for ID persistence\u2014no custom centroid tracker required\n",
    "- **Better Codec**: Used mp4v codec directly instead of MJPG + ffmpeg conversion\n",
    "- **Frame Preservation**: Processed every frame without skipping to maintain smooth playback\n",
    "- **Proper FPS**: Ensured output videos maintain the source frame rate\n",
    "- **Vehicle Counting**: Simple line-crossing algorithm using YOLO track IDs so each vehicle is counted only once\n",
    "\n",
    "### How Vehicle Counting Works:\n",
    "1. A horizontal green line is drawn roughly 2/3 down each frame\n",
    "2. When a vehicle's center crosses this line, it is counted\n",
    "3. YOLO track IDs ensure each vehicle is counted only once (55-pixel threshold)\n",
    "4. The current count is displayed in the top-left corner of each frame\n",
    "\n",
    "Both DIP R1 and L2 improve visibility in low-light conditions\u2014review their side-by-side outputs to decide which enhancement best serves your downstream analytics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIPENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}